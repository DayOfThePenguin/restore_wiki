{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0abea45b7c973306de9d802c3ee3e552deda7e2de4577ad1341732b7a50741558",
   "display_name": "Python 3.8.10  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "abea45b7c973306de9d802c3ee3e552deda7e2de4577ad1341732b7a50741558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Iterator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "# enwiki-20210520-page Stats\n",
    "- 6265 INSERT lines\n",
    "- 6,301,566 pages in ns0\n",
    "- max page_id: 67,715,788 (unsigned 32 bit int can represent 4,294,967,295, so it is safe to use np.uint32 for page_id)\n",
    "\n",
    "## INSERT entry format\n",
    "```python\n",
    "(10,0,'AccessibleComputing','',1,0,0.33167112649574004,'20210427193048','20210126121900',1002250816,111,'wikitext',NULL)\n",
    "page_id, page_ns, page_title\n",
    "```\n",
    "### Relevant groups:\n",
    "- 1: page_id\n",
    "- 2: page_ns\n",
    "- 3: page_title\n",
    "- 5: page_is_redirect (1: yes, 0: no)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_start = re.compile(b\"INSERT INTO (.*?) VALUES \")\n",
    "item_ex = re.compile(b\"\\((.*?),(.*?),'(.*?)',(.*?),(.*?),(.*?)\\)\")\n",
    "pages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_iterator(line) -> Iterator:\n",
    "    if line_start.search(line) is not None:\n",
    "        item_iter = item_ex.finditer(line)\n",
    "        return item_iter\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_pages_in_ns(line_iter, ns=0):\n",
    "    for entry in line_iter:\n",
    "        ns_b_string = bytes(f\"{ns}\", 'utf-8')\n",
    "        if entry.group(2) == ns_b_string and entry.group(5) == b'0':\n",
    "            pages.append([entry.group(1), entry.group(3)])\n",
    "            if len(pages) % 500000 == 0:\n",
    "                print(f\"matched {len(pages)} pages\")\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "def process_line(line, ns=0):\n",
    "    line_iter = get_line_iterator(line)\n",
    "    if line_iter is None:\n",
    "        return 0\n",
    "    find_pages_in_ns(line_iter, ns=ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "matched 500000 pages\n",
      "matched 1000000 pages\n",
      "matched 1500000 pages\n",
      "matched 2000000 pages\n",
      "matched 2500000 pages\n",
      "matched 3000000 pages\n",
      "matched 3500000 pages\n",
      "matched 4000000 pages\n",
      "matched 4500000 pages\n",
      "matched 5000000 pages\n",
      "matched 5500000 pages\n",
      "matched 6000000 pages\n",
      "matched 6500000 pages\n",
      "matched 7000000 pages\n"
     ]
    }
   ],
   "source": [
    "namespace = 1\n",
    "with open(\"data/enwiki-20210520-page.sql\", \"rb\") as file:\n",
    "    for line in file:\n",
    "        if line_start.search(line) is not None:\n",
    "            process_line(line, ns=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array=np.array(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'416541', b'Anarchism']\n"
     ]
    }
   ],
   "source": [
    "for page in pages:\n",
    "    if page[1] == b'Anarchism':\n",
    "        print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7043782"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "source": [
    "np.save(f\"ns{namespace}_pages\", np_array)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'5'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "val = 5\n",
    "bytes(f\"{val}\", 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pages = np.load(\"ns0_pages.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Duplicate page_id found:\n",
      "b'12'\n",
      "b'Anarchism' b'Anarchism'\n",
      "Duplicate page_id found:\n",
      "b'12'\n",
      "b'Anarchism' b'Anarchism'\n",
      "Duplicate page_id found:\n",
      "b'25'\n",
      "b'Autism' b'Autism'\n",
      "Duplicate page_id found:\n",
      "b'25'\n",
      "b'Autism' b'Autism'\n",
      "Duplicate page_id found:\n",
      "b'39'\n",
      "b'Albedo' b'Albedo'\n",
      "Duplicate page_id found:\n",
      "b'39'\n",
      "b'Albedo' b'Albedo'\n",
      "Duplicate page_id found:\n",
      "b'272'\n",
      "b'AcademicElitism' b'AcademicElitism'\n",
      "Duplicate page_id found:\n",
      "b'272'\n",
      "b'AcademicElitism' b'AcademicElitism'\n",
      "Duplicate page_id found:\n",
      "b'290'\n",
      "b'A' b'A'\n",
      "Duplicate page_id found:\n",
      "b'290'\n",
      "b'A' b'A'\n",
      "Duplicate page_id found:\n",
      "b'303'\n",
      "b'Alabama' b'Alabama'\n",
      "Duplicate page_id found:\n",
      "b'303'\n",
      "b'Alabama' b'Alabama'\n",
      "Duplicate page_id found:\n",
      "b'305'\n",
      "b'Achilles' b'Achilles'\n",
      "Duplicate page_id found:\n",
      "b'305'\n",
      "b'Achilles' b'Achilles'\n",
      "Duplicate page_id found:\n",
      "b'307'\n",
      "b'Abraham_Lincoln' b'Abraham_Lincoln'\n",
      "Duplicate page_id found:\n",
      "b'307'\n",
      "b'Abraham_Lincoln' b'Abraham_Lincoln'\n",
      "Duplicate page_id found:\n",
      "b'308'\n",
      "b'Aristotle' b'Aristotle'\n",
      "Duplicate page_id found:\n",
      "b'308'\n",
      "b'Aristotle' b'Aristotle'\n",
      "Duplicate page_id found:\n",
      "b'309'\n",
      "b'An_American_in_Paris' b'An_American_in_Paris'\n",
      "Duplicate page_id found:\n",
      "b'309'\n",
      "b'An_American_in_Paris' b'An_American_in_Paris'\n",
      "Duplicate page_id found:\n",
      "b'316'\n",
      "b'Academy_Award_for_Best_Production_Design' b'Academy_Award_for_Best_Production_Design'\n",
      "Duplicate page_id found:\n",
      "b'316'\n",
      "b'Academy_Award_for_Best_Production_Design' b'Academy_Award_for_Best_Production_Design'\n",
      "Duplicate page_id found:\n",
      "b'324'\n",
      "b'Academy_Awards' b'Academy_Awards'\n",
      "Duplicate page_id found:\n",
      "b'324'\n",
      "b'Academy_Awards' b'Academy_Awards'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3fa1005859c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp_pages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mfirst_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_match\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_pages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mfirst_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst_match\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_pages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(np_pages)):\n",
    "    for page in np_pages:\n",
    "        first_match = True\n",
    "        if first_match and (np_pages[i][0] == page[0]):\n",
    "            first_match = False\n",
    "        if not first_match and (np_pages[i][0] == page[0]):    \n",
    "            print(\"Duplicate page_id found:\")\n",
    "            print(np_pages[i][0])\n",
    "            print(np_pages[i][1], page[1])"
   ]
  }
 ]
}